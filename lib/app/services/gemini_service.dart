import 'dart:convert';
import 'dart:io';
import 'package:dio/dio.dart';
import 'package:flutter/foundation.dart';
import 'package:path_provider/path_provider.dart';
// ignore: depend_on_referenced_packages
import 'package:mime/mime.dart';
import 'package:voa_clone/app/constants/value.dart';
import 'package:voa_clone/model/lyric.dart';
import 'package:shared_preferences/shared_preferences.dart';

class GeminiService {
  final Dio _dio = Dio();
  final String baseUrl = "https://generativelanguage.googleapis.com/v1beta";
  final String apiKey = GeminiApiKey.key;

  // Cache ƒë·ªÉ l∆∞u lyrics ƒë√£ generate trong b·ªô nh·ªõ (trong m·ªôt phi√™n)
  final Map<String, List<Lyric>> _memoryCacheMap = {};

  // Key cho SharedPreferences ƒë·ªÉ l∆∞u th√¥ng tin cache
  static const String _lyricsStorageKey = 'gemini_lyrics_cache_keys';

  // Kh·ªüi t·∫°o SharedPreferences
  Future<SharedPreferences> get _prefs => SharedPreferences.getInstance();

  // T·∫°o key cho cache t·ª´ audioUrl v√† htmlContent
  String _createCacheKey(String audioUrl, String htmlContent) {
    // S·ª≠ d·ª•ng hash ƒë∆°n gi·∫£n ƒë·ªÉ r√∫t g·ªçn key
    final contentHash = htmlContent.hashCode.toString();
    final urlLastPart = audioUrl.split('/').last;
    return '$urlLastPart-$contentHash';
  }

  // Ki·ªÉm tra xem c√≥ lyrics trong cache kh√¥ng (b·ªô nh·ªõ ho·∫∑c local storage)
  Future<List<Lyric>?> _checkCache(String audioUrl, String htmlContent) async {
    final cacheKey = _createCacheKey(audioUrl, htmlContent);

    // Ki·ªÉm tra cache trong b·ªô nh·ªõ tr∆∞·ªõc
    if (_memoryCacheMap.containsKey(cacheKey)) {
      if (kDebugMode) {
        print('‚úÖ Lyrics found in memory cache');
      }
      return _memoryCacheMap[cacheKey];
    }

    // N·∫øu kh√¥ng c√≥ trong b·ªô nh·ªõ, ki·ªÉm tra trong local storage
    try {
      final prefs = await _prefs;
      final String? cachedLyricsJson = prefs.getString(cacheKey);

      if (cachedLyricsJson != null) {
        if (kDebugMode) {
          print('‚úÖ Lyrics found in disk cache');
        }
        // Chuy·ªÉn ƒë·ªïi JSON th√†nh danh s√°ch Lyric
        final List<dynamic> lyricsData = jsonDecode(cachedLyricsJson);
        final lyrics =
            lyricsData.map((data) {
              return Lyric(
                timestamp: Duration(milliseconds: data['timestamp']),
                text: data['text'],
              );
            }).toList();

        // L∆∞u v√†o b·ªô nh·ªõ ƒë·ªÉ truy c·∫≠p nhanh h∆°n l·∫ßn sau
        _memoryCacheMap[cacheKey] = lyrics;

        return lyrics;
      }
    } catch (e) {
      if (kDebugMode) {
        print('‚ùå Error reading from disk cache: $e');
      }
    }

    return null;
  }

  // L∆∞u lyrics v√†o c·∫£ b·ªô nh·ªõ v√† local storage
  Future<void> _saveLyricsToCache(
    String audioUrl,
    String htmlContent,
    List<Lyric> lyrics,
  ) async {
    final cacheKey = _createCacheKey(audioUrl, htmlContent);

    // L∆∞u v√†o b·ªô nh·ªõ
    _memoryCacheMap[cacheKey] = lyrics;

    // L∆∞u v√†o local storage
    try {
      final prefs = await _prefs;

      // Chuy·ªÉn ƒë·ªïi danh s√°ch Lyric th√†nh d·∫°ng c√≥ th·ªÉ l∆∞u ƒë∆∞·ª£c
      final lyricsData =
          lyrics.map((lyric) {
            return {
              'timestamp': lyric.timestamp.inMilliseconds,
              'text': lyric.text,
            };
          }).toList();

      // L∆∞u th√†nh JSON string
      final lyricsJson = jsonEncode(lyricsData);
      await prefs.setString(cacheKey, lyricsJson);

      // C·∫≠p nh·∫≠t danh s√°ch keys ƒë√£ l∆∞u tr·ªØ
      final cachedKeys = prefs.getStringList(_lyricsStorageKey) ?? [];
      if (!cachedKeys.contains(cacheKey)) {
        cachedKeys.add(cacheKey);
        await prefs.setStringList(_lyricsStorageKey, cachedKeys);
      }

      if (kDebugMode) {
        print('‚úÖ Lyrics saved to disk cache');
      }
    } catch (e) {
      if (kDebugMode) {
        print('‚ùå Error writing to disk cache: $e');
      }
    }
  }

  // X√≥a cache c≈© n·∫øu s·ªë l∆∞·ª£ng entries qu√° nhi·ªÅu (d·ªçn d·∫πp t·ª± ƒë·ªông)
  Future<void> _cleanupCache(int maxEntries) async {
    try {
      final prefs = await _prefs;
      final cachedKeys = prefs.getStringList(_lyricsStorageKey) ?? [];

      if (cachedKeys.length > maxEntries) {
        // X√≥a c√°c entries c≈© nh·∫•t (gi·ªØ l·∫°i maxEntries entries m·ªõi nh·∫•t)
        final keysToRemove = cachedKeys.sublist(
          0,
          cachedKeys.length - maxEntries,
        );
        final keysToKeep = cachedKeys.sublist(cachedKeys.length - maxEntries);

        for (final key in keysToRemove) {
          await prefs.remove(key);
        }

        await prefs.setStringList(_lyricsStorageKey, keysToKeep);
        if (kDebugMode) {
          print('üßπ Cleaned up ${keysToRemove.length} old cache entries');
        }
      }
    } catch (e) {
      if (kDebugMode) {
        print('‚ùå Error cleaning cache: $e');
      }
    }
  }

  /// 1Ô∏è‚É£ B∆∞·ªõc 1: L·∫•y URL t·∫£i l√™n t·ª´ Google
  Future<String?> getUploadUrl(File file) async {
    try {
      final mimeType = lookupMimeType(file.path) ?? 'audio/mp3';
      final numBytes = await file.length();

      Response response = await _dio.post(
        "$baseUrl/media/upload?key=$apiKey",
        options: Options(
          headers: {
            'Content-Type': 'application/json',
            'X-Upload-Content-Type': mimeType,
            'X-Upload-Content-Length': numBytes.toString(),
          },
        ),
        data: {'name': file.uri.pathSegments.last, 'mimeType': mimeType},
      );

      final location = response.headers.value('x-goog-upload-url');
      if (location == null) {
        throw Exception('No upload URL in response');
      }
      return location;
    } catch (e) {
      if (kDebugMode) {
        print("‚ùå L·ªói l·∫•y upload URL: $e");
      }
      return null;
    }
  }

  /// 2Ô∏è‚É£ B∆∞·ªõc 2: T·∫£i file l√™n Google
  Future<String?> uploadFile(String uploadUrl, File file) async {
    try {
      final bytes = await file.readAsBytes();

      Response response = await _dio.put(
        uploadUrl,
        data: Stream.fromIterable([bytes]),
        options: Options(
          headers: {
            'Content-Type': 'application/octet-stream',
            'Content-Length': bytes.length.toString(),
          },
        ),
      );

      if (response.statusCode != 200) {
        throw Exception('Upload failed with status ${response.statusCode}');
      }

      return response.data['name']; // Return the file ID/name
    } catch (e) {
      if (kDebugMode) {
        print("‚ùå L·ªói t·∫£i file l√™n: $e");
      }
      return null;
    }
  }

  /// 3Ô∏è‚É£ B∆∞·ªõc 3: G·ª≠i y√™u c·∫ßu t·∫°o n·ªôi dung t·ª´ file ƒë√£ t·∫£i l√™n
  Future<String?> generateContent(String fileUri, String htmlContent) async {
    try {
      Response response = await _dio.post(
        "$baseUrl/models/gemini-2.0-flash-lite:generateContent?key=$apiKey",
        options: Options(headers: {"Content-Type": "application/json"}),
        data: jsonEncode({
          "contents": [
            {
              "parts": [
                {
                  "text": '''
                    # HIGH-PRECISION LRC GENERATION SYSTEM

                    You are a specialized AI system for creating perfectly synchronized LRC files from audio and text content. Your task requires exceptional precision in both text matching and timing alignment.

                    ## PREPARATION PROCESS

                    1. PRELIMINARY TEXT ANALYSIS:
                       - First, thoroughly analyze the provided HTML text
                       - Extract all full sentences and paragraphs exactly as written
                       - Do NOT modify the original text in any way
                       - Identify and mark sentence boundaries, paragraph breaks, and potential challenging pronunciation points
                       - Create a sequential text map to ensure no content is missed or duplicated

                    2. AUDIO SEGMENTATION:
                       - Divide the audio into 30-second segments for analysis
                       - For each segment, identify clear audio markers (sentence starts, pauses, distinct words)
                       - Use these markers as synchronization checkpoints
                       - Process each segment independently, then verify continuity across segment boundaries

                    3. SYNCHRONIZATION PROTOCOL:
                       - Match each audio segment with its corresponding text section
                       - For each identified phrase in the audio:
                         a) Record the exact timestamp when the phrase begins
                         b) Extract the exact matching text from the HTML content
                         c) Create an LRC line in format [mm:ss.xx]exact text
                       - When uncertain about a word's pronunciation or timing:
                         a) Use surrounding context to infer position
                         b) Place timestamp slightly BEFORE the estimated start time
                         c) Cross-verify with nearby clear audio markers

                    ## MANDATORY QUALITY STANDARDS

                    1. ABSOLUTE TEXT FIDELITY:
                       - Each LRC line must contain EXACT text from the HTML, with no modifications
                       - Preserve all original capitalization, punctuation, and spacing
                       - Never substitute, rephrase, or summarize text
                       - Include ALL content from the HTML in the same order

                    2. TIMESTAMP PRECISION PROTOCOL:
                       - Use millisecond-precise timestamps: [mm:ss.xx]
                       - Apply the Recalibration Rule: At least every 30 seconds, find a clear audio marker to reset timing
                       - Implement Drift Correction: If timing becomes misaligned, return to the nearest clear audio point
                       - Always ensure timestamps are strictly sequential
                       - Round timestamps to nearest 100ms (xx value multiple of 10) for stability

                    3. SEGMENTATION GUIDELINES:
                       - Optimal segment length: 5-15 words per line
                       - Break at natural sentence or clause boundaries
                       - Balance readability with timing precision
                       - Avoid excessively long or short segments
                       - For very short phrases, combine only if spoken together without pause

                    ## ERROR PREVENTION STRATEGIES

                    1. MISALIGNMENT PREVENTION:
                       - Reset timing reference points at clear speech markers every 20-30 seconds
                       - When uncertainty occurs, prioritize text sequence integrity over uncertain pronunciations
                       - If timing drift is detected, recalibrate at next clear audio point
                       - For sections with unclear audio, mark timestamps based on surrounding clear sections

                    2. HANDLING CHALLENGING AUDIO:
                       - For mispronunciations or unclear speech: Follow the text as written, not as spoken
                       - For specialized terminology: Pay extra attention to exact pronunciation timing
                       - For background noise/music: Focus on vocal elements only
                       - For very fast speech: Break into shorter segments, maintaining text integrity

                    ## OUTPUT SPECIFICATION

                    Generate LRC content in this exact format:
                    [00:00.00]First text segment exactly matching HTML
                    [00:03.50]Second text segment exactly matching HTML
                    [00:07.90]Third text segment exactly matching HTML

                    Your output must:
                    - Include ONLY the LRC content (no explanations or comments)
                    - Contain every piece of text from the HTML
                    - Have precise, accurate timestamps
                    - Follow strict chronological order
                    - Be ready for immediate use in a media player
                  ''',
                },
                {
                  "audio": {"mime_type": "audio/mp3", "data": fileUri},
                },
                {"text": htmlContent},
              ],
            },
          ],
        }),
      );

      if (response.statusCode != 200) {
        throw Exception(
          'Generate content failed with status ${response.statusCode}',
        );
      }

      return response.data['candidates']?[0]['content']['parts']?[0]['text'];
    } catch (e) {
      if (kDebugMode) {
        print("‚ùå L·ªói t·∫°o n·ªôi dung: $e");
      }
      return null;
    }
  }

  Future<List<Lyric>> generateLyrics(
    String audioUrl,
    String htmlContent,
  ) async {
    try {
      // Ki·ªÉm tra cache tr∆∞·ªõc
      final cachedLyrics = await _checkCache(audioUrl, htmlContent);
      if (cachedLyrics != null && cachedLyrics.isNotEmpty) {
        return cachedLyrics;
      }

      // 1. T·∫£i file audio v·ªõi chunk size nh·ªè h∆°n
      final audioFile = await _downloadAudioWithChunks(audioUrl);
      if (audioFile == null) {
        throw Exception('Failed to download audio file');
      }

      // 2. Chuy·ªÉn file audio th√†nh base64 v·ªõi chunk size
      final base64Audio = await _encodeAudioToBase64(audioFile);

      // 3. G·ªçi API Gemini v·ªõi prompt ƒë∆∞·ª£c c·∫£i thi·ªán
      final response = await _dio.post(
        "$baseUrl/models/gemini-2.0-flash:generateContent?key=$apiKey",
        options: Options(
          headers: {"Content-Type": "application/json"},
          validateStatus: (status) => status! < 500,
        ),
        data: {
          "contents": [
            {
              "parts": [
                {
                  "text": '''
                    # H∆Ø·ªöNG D·∫™N T·∫†O LRC FILE CH√çNH X√ÅC

                    B·∫°n l√† m·ªôt h·ªá th·ªëng AI chuy√™n bi·ªát ƒë·ªÉ t·∫°o file LRC ƒë·ªìng b·ªô t·ª´ audio v√† vƒÉn b·∫£n. Nhi·ªám v·ª• c·ªßa b·∫°n l√† t·∫°o ra file LRC v·ªõi ƒë·ªô ch√≠nh x√°c cao nh·∫•t c√≥ th·ªÉ.

                    ## QUY T·∫ÆC CH√çNH

                    1. ƒê·ªäNH D·∫†NG OUTPUT:
                       - M·ªói d√≤ng PH·∫¢I theo format ch√≠nh x√°c: [mm:ss.xx]text
                       - mm: ph√∫t (00-99)
                       - ss: gi√¢y (00-59)
                       - xx: mili gi√¢y (00-99)
                       - text: n·ªôi dung vƒÉn b·∫£n CH√çNH X√ÅC t·ª´ HTML
                       
                    2. ƒê·ªíNG B·ªò TH·ªúI GIAN:
                       - Timestamp ph·∫£i CH√çNH X√ÅC v·ªõi th·ªùi ƒëi·ªÉm b·∫Øt ƒë·∫ßu c·ªßa t·ª´ng c√¢u trong audio
                       - Kho·∫£ng c√°ch t·ªëi thi·ªÉu gi·ªØa c√°c timestamp: 200ms
                       - Kh√¥ng ƒë∆∞·ª£c c√≥ timestamp tr√πng l·∫∑p
                       - Timestamp ph·∫£i theo th·ª© t·ª± tƒÉng d·∫ßn
                       
                    3. N·ªòI DUNG VƒÇN B·∫¢N:
                       - Copy CH√çNH X√ÅC t·ª´ HTML, kh√¥ng thay ƒë·ªïi/th√™m/b·ªõt
                       - Gi·ªØ nguy√™n d·∫•u c√¢u, ch·ªØ hoa/th∆∞·ªùng
                       - Chia c√¢u d·ª±a v√†o ng·ªØ ƒëi·ªáu ng∆∞·ªùi n√≥i
                       - M·ªói d√≤ng n√™n c√≥ ƒë·ªô d√†i v·ª´a ph·∫£i (5-15 t·ª´)

                    ## X·ª¨ L√ù TR∆Ø·ªúNG H·ª¢P ƒê·∫∂C BI·ªÜT

                    1. Khi audio kh√¥ng r√µ:
                       - V·∫´n s·ª≠ d·ª•ng text t·ª´ HTML
                       - ƒê·∫∑t timestamp d·ª±a v√†o context xung quanh
                       
                    2. Khi ng∆∞·ªùi n√≥i qu√° nhanh:
                       - Chia th√†nh c√°c ƒëo·∫°n ng·∫Øn h∆°n
                       - ƒê·∫£m b·∫£o v·∫´n gi·ªØ nguy√™n text g·ªëc
                       
                    3. Khi c√≥ nhi·ªÖu/nh·∫°c n·ªÅn:
                       - T·∫≠p trung v√†o gi·ªçng n√≥i ch√≠nh
                       - B·ªè qua c√°c √¢m thanh ph·ª•

                    ## V√ç D·ª§ OUTPUT MONG MU·ªêN

                    [00:00.00]This is the first line of the text
                    [00:02.50]It should match exactly with the HTML content
                    [00:05.80]And be perfectly synchronized with the audio
                    [00:08.20]Each timestamp should be precise
                    [00:10.50]And follow a logical sequence

                    ## L∆ØU √ù QUAN TR·ªåNG

                    - CH·ªà tr·∫£ v·ªÅ n·ªôi dung LRC, kh√¥ng k√®m gi·∫£i th√≠ch
                    - ƒê·∫¢M B·∫¢O bao g·ªìm to√†n b·ªô n·ªôi dung t·ª´ HTML
                    - KI·ªÇM TRA k·ªπ c√°c timestamp tr∆∞·ªõc khi tr·∫£ v·ªÅ
                    - KH√îNG ƒë∆∞·ª£c b·ªè s√≥t ho·∫∑c th√™m n·ªôi dung
                  ''',
                },
                {
                  "inline_data": {
                    "mime_type": "audio/mp3",
                    "data": base64Audio,
                  },
                },
                {"text": htmlContent},
              ],
            },
          ],
        },
      );

      if (response.statusCode != 200) {
        if (kDebugMode) {
          print("API Response: ${response.data}");
        }
        throw Exception(
          'Generate content failed with status ${response.statusCode}',
        );
      }

      final content =
          response.data['candidates']?[0]['content']['parts']?[0]['text'];
      if (content == null) {
        throw Exception('No content in response');
      }

      // Parse v√† l√†m tr√≤n th·ªùi gian
      final lyrics = _parseLrcContent(content);

      // L∆∞u v√†o cache (b·ªô nh·ªõ v√† ƒëƒ©a)
      if (lyrics.isNotEmpty) {
        await _saveLyricsToCache(audioUrl, htmlContent, lyrics);
        // D·ªçn d·∫πp cache c≈© n·∫øu c·∫ßn (gi·ªØ t·ªëi ƒëa 50 b√†i)
        await _cleanupCache(50);
      }

      return lyrics;
    } catch (e) {
      if (kDebugMode) {
        print('Error generating lyrics: $e');
      }
      return [];
    } finally {
      // X√≥a file t·∫°m n·∫øu t·ªìn t·∫°i
      try {
        final tempDir = await getTemporaryDirectory();
        final fileName = audioUrl.split('/').last;
        final file = File('${tempDir.path}/$fileName');
        if (await file.exists()) {
          await file.delete();
        }
      } catch (e) {
        if (kDebugMode) {
          print('Error cleaning up temp file: $e');
        }
      }
    }
  }

  Future<File?> _downloadAudioWithChunks(String url) async {
    try {
      final tempDir = await getTemporaryDirectory();
      final fileName = url.split('/').last;
      final file = File('${tempDir.path}/$fileName');

      if (await file.exists()) {
        return file;
      }

      final response = await _dio.get(
        url,
        options: Options(
          responseType: ResponseType.stream,
          validateStatus: (status) => status! < 500,
        ),
      );

      final sink = file.openWrite();
      await for (final chunk in response.data.stream) {
        sink.add(chunk);
      }
      await sink.close();

      return file;
    } catch (e) {
      if (kDebugMode) {
        print('Error downloading audio: $e');
      }
      return null;
    }
  }

  Future<String> _encodeAudioToBase64(File file) async {
    final List<int> bytes = [];
    final stream = file.openRead();
    await for (final chunk in stream) {
      bytes.addAll(chunk);
    }
    return base64Encode(bytes);
  }

  List<Lyric> _parseLrcContent(String content) {
    final List<Lyric> lyrics = [];
    final lines = content.split('\n');
    Duration? lastTimestamp;

    for (var line in lines) {
      final match = RegExp(
        r'\[(\d{2}):(\d{2})\.(\d{2})\](.*)',
      ).firstMatch(line);

      if (match != null) {
        final minutes = int.parse(match.group(1)!);
        final seconds = int.parse(match.group(2)!);
        final milliseconds = int.parse(match.group(3)!);
        final text = match.group(4)?.trim() ?? '';

        if (text.isNotEmpty) {
          // L√†m tr√≤n th·ªùi gian ƒë·∫øn 100ms g·∫ßn nh·∫•t
          var timestamp = Duration(
            minutes: minutes,
            seconds: seconds,
            milliseconds:
                milliseconds * 10, // S·ª≠a l·ªói l√†m tr√≤n (gi·ªØ ƒë√∫ng milliseconds)
          );

          // ƒê·∫£m b·∫£o timestamp m·ªõi lu√¥n l·ªõn h∆°n timestamp c≈© √≠t nh·∫•t 50ms
          if (lastTimestamp != null && timestamp <= lastTimestamp) {
            timestamp = lastTimestamp + const Duration(milliseconds: 50);
          }
          // N·∫øu kho·∫£ng c√°ch qu√° nh·ªè (d∆∞·ªõi 200ms) v√† kh√¥ng ph·∫£i d√≤ng ƒë·∫ßu ti√™n, tƒÉng l√™n √≠t nh·∫•t 200ms
          else if (lastTimestamp != null &&
              timestamp - lastTimestamp < const Duration(milliseconds: 200) &&
              lyrics.isNotEmpty) {
            timestamp = lastTimestamp + const Duration(milliseconds: 200);
          }

          lastTimestamp = timestamp;
          lyrics.add(Lyric(timestamp: timestamp, text: text));
        }
      }
    }

    // Th√™m x·ª≠ l√Ω th√™m: ƒë·∫£m b·∫£o kho·∫£ng c√°ch h·ª£p l√Ω gi·ªØa c√°c d√≤ng
    if (lyrics.length > 1) {
      for (int i = 1; i < lyrics.length; i++) {
        // N·∫øu kho·∫£ng c√°ch qu√° ng·∫Øn (<200ms), tƒÉng th·ªùi gian
        var prevTime = lyrics[i - 1].timestamp;
        var currTime = lyrics[i].timestamp;

        if (currTime.inMilliseconds - prevTime.inMilliseconds < 200) {
          lyrics[i] = Lyric(
            timestamp: prevTime + const Duration(milliseconds: 200),
            text: lyrics[i].text,
          );
        }
      }
    }

    return lyrics;
  }
}
